---
title: "ISL Chapter 5: Lab & Applied Exercises"
author: "Momoko Price"
date: "07/29/2020"
output: 
  html_document:
    css: ch5.css
---

***
```{r default_setup, include=FALSE}
knitr::opts_chunk$set(include = T,
                      echo = F, 
                      message = F, 
                      warning = F,
                      fig.align = 'left',
                      out.width = '80%')

# global options
options(stringsAsFactors = F)
# Load libraries
require(tidyverse)
require(data.table)
require(ggplot2)
require(gridExtra)
require(PerformanceAnalytics)
require(magrittr)
require(MASS)
require(ISLR)

# Source files & custom functions
source("exploratory_data_functions.R")
```


#### 5.3 Lab: Cross-Validation and the Bootstrap

##### 5.3.1 The Validation Set Approach

In this lab, we explore the resampling techniques covered in this chapter. Some of the commands in this lab may take a while to run on your computer.

```{r validation_method, echo=F}
# load data
data(Auto)
# set seed for repeatable results
set.seed(1)
# set training & test data subset
train <- sample(392, 196) # total object length, first 196 obs
train.df <- Auto[train,]
test.df <- Auto[-train,]
test.outcomes <- Auto[-train,]$mpg

# linear regression fit
lm.fit <- lm(mpg ~ horsepower, data=train.df)
# generate predictions with test data (using -train)
lm.preds <- predict(lm.fit, test.df)
# calculate the MSE (mean squared error) of our predictions vs. the actual test outcomes
lm.squared.test.error <- (test.outcomes - lm.preds)^2
lm.fit.mse <- mean(lm.squared.test.error)


# quadratic & cubic regression fit
qd.fit <- lm(mpg ~ poly(horsepower,2), data=train.df)
cb.fit <- lm(mpg ~ poly(horsepower,3), data=train.df)
# generate predictions with test data (using -train)
qd.preds <- predict(qd.fit, test.df)
cb.preds <- predict(cb.fit, test.df)
# calculate the MSE (mean squared error) of our predictions vs. the actual test outcomes
qd.squared.test.error <- (test.outcomes - qd.preds)^2
cb.squared.test.error <- (test.outcomes - cb.preds)^2
# cubic regression fit
qd.fit.mse <- mean(qd.squared.test.error)
cb.fit.mse <- mean(cb.squared.test.error)

# best model based on min MSE
c("lm.fit.mse", "qd.fit.mse", "cb.fit.mse")[which.min(c(lm.fit.mse, qd.fit.mse, cb.fit.mse))]
```

##### 5.3.2 Leave-One-Out Cross-Validation

The LOOCV estimate can be automatically computed for any generalized linear model using the glm() and cv.glm() functions. Let's load the required package for cv.glm now (it's called "boot").

```{r loocv, echo=F}
require(boot)
loocv.fit.glm <- glm(mpg ~ horsepower, data = Auto)
loocv.cv.err <- cv.glm(Auto, loocv.fit.glm)
loocv.cv.err$delta # numbers correspond to the test MSE estimate for the fit; they should be virtually identical
```

That gave us an MSE estimate for an LOOCV-based linear regression of about 24.23 units (in this case, mpg). Let's run the same validation method on increasing polynomial regressions and see if we can improve / minimize the error:

```{r poly_loocv, echo=F}
poly.loocv.cv.err <- rep(0,5) # placeholders for each error calculations
for(i in 1:5) {
  poly.loocv.fit.glm <- glm(mpg ~ poly(horsepower, i), data = Auto)
  poly.loocv.cv.err[i] <- cv.glm(Auto, poly.loocv.fit.glm)$delta[1]
}
poly.loocv.cv.err
```
We see a significant improvement in MSE going from a linear to a quadratic fit, but higher order polynomials don't bring in further improvement, so the best option is quadratic. 

##### 5.3.3 k-Fold Cross-Validation
Since LOOCV is just k-fold CV with k = n, we can use the cv.glm() function to implement k-fold CV. Below we use k = 10, a common choice for k, on the Auto data set. 


```{r poly_k10, echo=F}
set.seed(17)
poly.k10.cv.err <- rep(0,10) # placeholders for each error calculations
for(i in 1:10) {
  poly.k10.fit.glm <- glm(mpg ~ poly(horsepower, i), data = Auto)
  poly.k10.cv.err[i] <- cv.glm(Auto, poly.k10.fit.glm, K=10)$delta[1]
}
poly.k10.cv.err
```
We saw in Section 5.3.2 that the two numbers associated with delta are essentially the same when LOOCV is performed. When we instead perform k-fold CV, then the two numbers associated with delta differ slightly. The first is the standard k-fold CV estimate, as in (5.3). The second is a bias-corrected version. On this data set, the two estimates are very similar to each other.

##### 5.3.4 The Bootstrap
One of the great advantages of the bootstrap approach is that it can be applied in almost all situations. No complicated mathematical calculations are required. Performing a bootstrap analysis in R entails only two steps. First, we must create a function that computes the statistic of interest. Second, we use the boot() function, which is part of the boot library, to perform the bootstrap by repeatedly sampling observations from the data set with replacement.

The Portfolio data set in the ISLR package is described in Section 5.2. To illustrate the use of the bootstrap on this data, we must first create a function, alpha.fn(), which takes as input the (X,Y) data as well as a vector indicating which observations should be used to estimate α. The function then outputs the estimate for α based on the selected observations.

Recall that 'alpha' in this case refers to the proportion of our cash that we'll invest in stock X (and the remainder, 1-alpha, in stock Y) that minimizes investment risk (variance) of both investments. See formula 5.7 on page 187 of the textbook for the actual formula for minimizing this variance. 

```{r bootstrap_func_setup, echo=F}
set.seed(1)
data(Portfolio)

alpha.fn <- function(data, index){
  X=data$X[index]
  Y=data$Y[index]
  return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}

alpha.fn(Portfolio, 1:100)
```
```{r bootstrap_sample_once, echo=F}

alpha.fn(Portfolio, sample(100,100, replace=T))

```
We can implement a bootstrap analysis by performing this command many times, recording all of the corresponding estimates for α, and computing the resulting standard deviation. 

Thankfully, the boot() function automates boot() this approach. Below we produce R = 1, 000 bootstrap estimates for α.

```{r boot, echo=F}

boot(data = Portfolio, alpha.fn, R=1000)

```
The bootstrap approach can be used to assess the variability of the coefficient estimates and predictions from a statistical learning method. Here we use the bootstrap approach in order to assess the variability of the estimates for β0 and β1, the intercept and slope terms for the linear regres- sion model that uses horsepower to predict mpg in the Auto data set.

```{r bootfunc_lm, echo=F}
# step 1 - define the function that generates the stats you want, in this case the intercept b0 and slope b1 of a linear regression fit of mpg ~ horsepower from the Auto data set:

boot.fn <- function(data, index) {
  return(coef(lm(mpg ~ horsepower, data = data, subset = index)))
}
boot.fn(Auto, 1:392)

# step 2 - generate an estimate by applying the function with a defined sample of the data set
boot.fn(Auto, sample(392, 392, replace=T))

# step 3 - use the boot() function to repeat the process R times and calculate the SE of your stats. 
boot(Auto, boot.fn, 1000)
```
```{r bootfunc_lm2, echo=F}
# step 1 - define the function that generates the stats you want, in this case the intercept b0 and slope b1 of a linear regression fit of mpg ~ horsepower from the Auto data set:

boot.fn2 <- function(data, index) {
  return(coef(lm(mpg ~ horsepower + I(horsepower^2), data = data, subset = index)))
}
boot.fn2(Auto, 1:392)

# step 2 - generate an estimate by applying the function with a defined sample of the data set
boot.fn2(Auto, sample(392, 392, replace=T))

# step 3 - use the boot() function to repeat the process R times and calculate the SE of your stats. 
boot(Auto, boot.fn2, 1000)
```

##### 5.3.4 Applied Problems

5. In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.

(a) Fit a logistic regression model that uses income and balance to predict default.

```{r 5a, echo=TRUE}
data(Default)
str(Default)

# use sample() to create a training index that takes 50% of the sample
sample.length <- nrow(Default)
sample.size <- sample.length/2
train.index <- sample(sample.length, sample.size)

# fit a logistic regression model
default.lm <- glm(default ~ balance + income, data = Default, subset = train.index, family="binomial")
summary(default.lm)

# make predictions
default.lm.probs <- predict(default.lm, 
                            newdata = Default[-train.index,],
                            type = "response")
default.lm.preds <- rep("No", nrow(Default[-train.index,]))
default.lm.preds[default.lm.probs > 0.1] = "Yes"

# isolate test outcomes
default.lm.test.outcomes <- Default[-train.index,]$default

# check test error via confusion matrix
c.matrix <- table(default.lm.preds, default.lm.test.outcomes)
test.error <- mean(default.lm.preds != default.lm.test.outcomes)

# false positives
type1 <- c.matrix[2,1]/(c.matrix[1,1]+c.matrix[2,1])

# false negatives
type2 <- c.matrix[1,2]/(c.matrix[2,2]+c.matrix[1,2])
```
Hmmm, this model is TOO stringent, it's causing too many false negatives.  

