---
title: "ISL Chapter 5: Lab & Applied Exercises"
author: "Momoko Price"
date: "07/29/2020"
output: 
  html_document:
    css: ch5.css
---

***
```{r default_setup, include=FALSE}
knitr::opts_chunk$set(include = T,
                      echo = F, 
                      message = F, 
                      warning = F,
                      fig.align = 'left',
                      out.width = '80%')

# global options
options(stringsAsFactors = F)
# Load libraries
require(tidyverse)
require(data.table)
require(ggplot2)
require(gridExtra)
require(PerformanceAnalytics)
require(magrittr)
require(MASS)
require(ISLR)

# Source files & custom functions
source("exploratory_data_functions.R")
```


#### 5.3 Lab: Cross-Validation and the Bootstrap

##### 5.3.1 The Validation Set Approach

In this lab, we explore the resampling techniques covered in this chapter. Some of the commands in this lab may take a while to run on your computer.

```{r validation_method, echo=F}
# load data
data(Auto)
# set seed for repeatable results
set.seed(1)
# set training & test data subset
train <- sample(392, 196) # total object length, first 196 obs
train.df <- Auto[train,]
test.df <- Auto[-train,]
test.outcomes <- Auto[-train,]$mpg

# linear regression fit
lm.fit <- lm(mpg ~ horsepower, data=train.df)
# generate predictions with test data (using -train)
lm.preds <- predict(lm.fit, test.df)
# calculate the MSE (mean squared error) of our predictions vs. the actual test outcomes
lm.squared.test.error <- (test.outcomes - lm.preds)^2
lm.fit.mse <- mean(lm.squared.test.error)


# quadratic & cubic regression fit
qd.fit <- lm(mpg ~ poly(horsepower,2), data=train.df)
cb.fit <- lm(mpg ~ poly(horsepower,3), data=train.df)
# generate predictions with test data (using -train)
qd.preds <- predict(qd.fit, test.df)
cb.preds <- predict(cb.fit, test.df)
# calculate the MSE (mean squared error) of our predictions vs. the actual test outcomes
qd.squared.test.error <- (test.outcomes - qd.preds)^2
cb.squared.test.error <- (test.outcomes - cb.preds)^2
# cubic regression fit
qd.fit.mse <- mean(qd.squared.test.error)
cb.fit.mse <- mean(cb.squared.test.error)

# best model based on min MSE
c("lm.fit.mse", "qd.fit.mse", "cb.fit.mse")[which.min(c(lm.fit.mse, qd.fit.mse, cb.fit.mse))]
```

##### 5.3.2 Leave-One-Out Cross-Validation

The LOOCV estimate can be automatically computed for any generalized linear model using the glm() and cv.glm() functions. Let's load the required package for cv.glm now (it's called "boot").

```{r loocv, echo=F}
require(boot)
loocv.fit.glm <- glm(mpg ~ horsepower, data = Auto)
loocv.cv.err <- cv.glm(Auto, loocv.fit.glm)
loocv.cv.err$delta # numbers correspond to the test MSE estimate for the fit; they should be virtually identical
```

That gave us an MSE estimate for an LOOCV-based linear regression of about 24.23 units (in this case, mpg). Let's run the same validation method on increasing polynomial regressions and see if we can improve / minimize the error:

```{r poly_loocv, echo=F}
poly.loocv.cv.err <- rep(0,5) # placeholders for each error calculations
for(i in 1:5) {
  poly.loocv.fit.glm <- glm(mpg ~ poly(horsepower, i), data = Auto)
  poly.loocv.cv.err[i] <- cv.glm(Auto, poly.loocv.fit.glm)$delta[1]
}
poly.loocv.cv.err
```
We see a significant improvement in MSE going from a linear to a quadratic fit, but higher order polynomials don't bring in further improvement, so the best option is quadratic. 

##### 5.3.3 k-Fold Cross-Validation


